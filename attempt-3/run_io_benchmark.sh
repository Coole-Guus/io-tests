#!/bin/bash

# Main orchestrator for the IO Performance Comparison Framework
# Coordinates all components to run comprehensive IO performance tests

# Don't exit on error - handle errors gracefully
set +e

# Get script directory for relative sourcing
SCRIPT_DIR="$(dirname "${BASH_SOURCE[0]}")"

# Source all modules
source "$SCRIPT_DIR/config.sh"
source "$SCRIPT_DIR/utils.sh"
source "$SCRIPT_DIR/cleanup.sh"
source "$SCRIPT_DIR/network_setup.sh"
source "$SCRIPT_DIR/firecracker_setup.sh"
source "$SCRIPT_DIR/container_setup.sh"
source "$SCRIPT_DIR/container_test_runner.sh"
source "$SCRIPT_DIR/firecracker_test_runner.sh"
source "$SCRIPT_DIR/analysis.sh"

# Main execution
main() {
    # Get selected test list first to show correct counts
    readarray -t selected_tests < <(get_test_list)
    local total_tests=${#selected_tests[@]}
    
    echo "=== COMPREHENSIVE IO PERFORMANCE COMPARISON FRAMEWORK ==="
    echo "ðŸ”¬ Testing Multiple Block Sizes: 512B, 4KB, 64KB, 1MB"
    echo "ðŸŽ¯ Testing Multiple Operations: Sequential/Random Read/Write, Mixed Workloads"
    echo "ðŸ“Š Data Sizes: 8MB (512B, 4K blocks), 10MB (64K blocks), 12MB (1M blocks)"
    echo "âš¡ Total Tests: $total_tests test patterns across both environments"
    echo "ðŸ“ Results will be saved to: $RESULTS_DIR"
    echo ""
    
    # Show test breakdown
    echo "ðŸ“‹ Test Matrix:"
    echo "   â€¢ Ultra-small (512B blocks): 2 tests - random read/write on 8MB files"
    echo "   â€¢ Small blocks (4KB): 4 tests - sequential/random operations on 8MB files" 
    echo "   â€¢ Medium blocks (64KB): 4 tests - sequential/random operations on 10MB files"
    echo "   â€¢ Large blocks (1MB): 4 tests - sequential/random operations on 12MB files"
    echo "   â€¢ Mixed workloads: 3 tests - randrw operations at different scales"
    echo "   â€¢ Total runtime estimate: ~$(($total_tests * 2 * $ITERATIONS * 12 / 60)) minutes"
    echo ""
    
    # Check prerequisites
    check_prerequisites
    
    # Setup components
    echo "ðŸš€ Setting up test environment..."
    setup_network
    setup_firecracker_vm
    setup_container
    
    # Verify storage backends are comparable
    echo ""
    echo "ðŸ“Š Storage Backend Verification:"
    echo "================================="
    echo "âœ… Both environments now use raw block devices with ext4 filesystem"
    echo "âœ… Firecracker: virtio-blk device (/dev/vdb) â†’ /mnt/test_data"
    echo "âœ… Docker: loop device (/dev/test_disk) â†’ /mnt/test_data"
    echo "âœ… Both use identical filesystem (ext4) and mount options"
    echo "âœ… Direct I/O flags removed for consistent caching behavior"
    echo ""
    
    echo "ðŸš€ Starting comprehensive IO tests across multiple block sizes..."
    
    if [ $total_tests -eq 0 ]; then
        echo "âŒ No tests selected based on current filters"
        exit 1
    fi
    
    echo "ðŸ“ Selected tests: $total_tests/${#IO_PATTERNS[@]} total patterns"
    
    # Run tests for each selected pattern
    local test_count=0
    
    for pattern_name in "${selected_tests[@]}"; do
        test_count=$((test_count + 1))
        echo ""
        echo "ðŸ§ª [$test_count/$total_tests] Testing IO Pattern: $pattern_name"
        echo "=============================================================="
        
        command="${IO_PATTERNS[$pattern_name]}"
        
        # Test container performance
        echo "ðŸ“¦ Testing container performance..."
        monitor_pids=$(monitor_system_metrics "$pattern_name" $((ITERATIONS * 3)) "container_${pattern_name}")
        run_container_io_test "$pattern_name" "$command" "${RESULTS_DIR}/container_${pattern_name}.csv"
        stop_monitoring "$monitor_pids"
        
        echo "   Container testing complete, waiting 5s..."
        sleep 5
        
        # Test Firecracker performance
        echo "ðŸ”¥ Testing Firecracker performance..."
        monitor_pids=$(monitor_system_metrics "$pattern_name" $((ITERATIONS * 3)) "firecracker_${pattern_name}")
        run_firecracker_io_test "$pattern_name" "$command" "${RESULTS_DIR}/firecracker_${pattern_name}.csv"
        stop_monitoring "$monitor_pids"
        
        echo "   Firecracker testing complete, waiting 5s..."
        sleep 5
        
        # Progress update
        local remaining=$((total_tests - test_count))
        if [ $remaining -gt 0 ]; then
            echo "   â³ $remaining tests remaining..."
        fi
    done
    
    # Analysis
    echo ""
    echo "ðŸ“Š Generating comprehensive performance analysis..."
    analyze_results
    
    echo ""
    echo "ðŸŽ‰ COMPREHENSIVE EXPERIMENT COMPLETE!"
    echo "==============================================="
    echo "ðŸ“ All results saved to: $RESULTS_DIR"
    echo ""
    echo "ðŸ“„ Generated Files:"
    echo "   â€¢ ${#IO_PATTERNS[@]} container_*.csv files - Container performance data"
    echo "   â€¢ ${#IO_PATTERNS[@]} firecracker_*.csv files - Firecracker performance data"
    echo "   â€¢ Multiple *_cpu.log files - CPU utilization during tests"
    echo "   â€¢ analyze_results.py - Advanced analysis script"
    echo "   â€¢ firecracker-io-test.log - VM execution logs"
    echo ""
    echo "ðŸ” Key Analysis Features:"
    echo "   â€¢ Block size performance comparison (512B â†’ 1MB)"
    echo "   â€¢ Operation type analysis (Sequential/Random/Mixed)"
    echo "   â€¢ Performance improvement percentages"
    echo "   â€¢ Recommendations for optimal use cases"
}

# Execute main function
main "$@"
